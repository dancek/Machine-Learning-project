\section{Discussion} \label{sec:discussion}

In the Bernoulli mixture, we weighted the classes' posterior
probabilities with the classes' prior probabilities. This seemed to
improve the Bernoulli mixture as it superseded the other two methods in
test accuracies. Similar weighting could have been done with the other
two methods. However, this would not have been so well justified as the
other methods are not probabilistic by nature and it is arguable whether
we can interpret their outputs as probabilities. Therefore, it is not
meaningful to try draw any probabilistic interpretations for taking the
mean of the classifiers' outputs. Instead, this operation should be
regarded as a simple heuristic trick that proved to be useful.

The 448 dimensional data we classified contained probably lots of
insignificant or redundant information that did not contribute to the
classification. Therefore, some feature extraction methods could have
been tested to make the classification task easier for the different
classifiers. For example, the EM algorithm used with the Bernoulli
mixture is time consuming and may find only local optima. The parameter
optimization, whose results are shown in Figure \ref{fig:bmix}, took
about one week to complete with a standard desktop and the accuracies
over different folds varied. More parameter combinations and repetitions
could have been calculated after applying, e.g., binary PCA to the data.
An alternative approach would have been to use feature selection where
we try find only the variables that contribute to the classification
task.

Another ways to improve the classification could have been to try out a
more broad set of base learners and different ways of combining these.
For example, boosting or bagging could have been tested.

\section{Conclusions}

We applied an ensemble method for classifying multivariate binary data
representing ham and spam messages. Three state-of-the-art classifiers,
namely a support vector machine, a Bernoulli mixture and a Random Forest
classifier were used, choosing the model parameters with 10-fold
cross-validation. High cross-validation and test accuracies ranging from
$96.3 \%$ to $98.4 \%$ were obtained with each of the classifiers.

The classifiers gave continuous output values from 0 to 1 and the
ensemble was selected as the mean of these values. The ensemble
cross-validation accuracy ($99.2 \%$) clearly superseded that of each
individual classifier. The ensemble test accuracy was equal to the test
accuracy of Bernoulli mixture which had the best performance on the test
set. Consequently, we succeeded in our mission to select versatile
classifiers that complement each other.
